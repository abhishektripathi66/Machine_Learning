{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a3a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ff9903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357bfbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"../Data/airlines_flights_data.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b77cb8",
   "metadata": {},
   "source": [
    "to find the size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7a3e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f88458",
   "metadata": {},
   "source": [
    "Find the null value in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2722a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c1098",
   "metadata": {},
   "source": [
    "to have the pattern understanding we would be converting it to percentage null values, to find which content we want to keep and which we want to discard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680b04fc",
   "metadata": {},
   "source": [
    "shape[0] gives the number of rows in the dataset, shape[1] gives the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d707487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()/dataset.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85241408",
   "metadata": {},
   "source": [
    "to find the total number of null values we use dataset.isnull().sum().sum()\n",
    "To find the percentage of null values overall (dataset.isnull().sum().sum()/(dataset.shape[0]*dataset.shape[1]))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4da6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset.isnull().sum().sum()/(dataset.shape[0]*dataset.shape[1]))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4efa3a8",
   "metadata": {},
   "source": [
    "how many not null vlaues are present in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9aae47",
   "metadata": {},
   "source": [
    "in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e46c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.notnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f71245",
   "metadata": {},
   "source": [
    "overall null vlaue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e108a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.notnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e06b7",
   "metadata": {},
   "source": [
    "To make graph of the not null values we would be importing seaborn, and from matplotlib we would be importing pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c3bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ec12c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f62a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dataset.isnull())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0656c2",
   "metadata": {},
   "source": [
    "now we have to see how we would be discarding the data that has missing values, if the total missing value is more than 50 % then there is no point in using that data as the nature identification of that data would be difficult. if its less than 50% we can consider the data.\n",
    "\n",
    "But we want to have a certain columns with less than 50 % then we have to add the missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086b180b",
   "metadata": {},
   "source": [
    "now we would be looking how we can delete the data thats not required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3387426",
   "metadata": {},
   "source": [
    "there are two ways delete, delete the column itself or delte that particular row, we can even add the data data as well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009be1c2",
   "metadata": {},
   "source": [
    "This will remove the column from the exisitng dataset, it wont be creating new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b4b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=[\"arrival_time\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d03a4",
   "metadata": {},
   "source": [
    "if we want to delte a row that has null values then we use dropna which removes all the NA values, inplace when set to True it means that the changes has to be done in the same dataset rather than creating a new set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74eafbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a642022d",
   "metadata": {},
   "source": [
    "now we would be seeing how to fill the data if our data is categorical\n",
    "first we have to find the data types of the dataset before filling the missing data, because we cannot just add any data to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../Data/airlines_flights_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1931d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f63368",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d79f220",
   "metadata": {},
   "source": [
    "we fill data using the fillna(\"the value to be added\") method and head(number of rows to display) is used for displaying the data upto certain number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccca1161",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fillna(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257696f7",
   "metadata": {},
   "source": [
    "we see above that irrespective of datatype of the column the fillna fills the same value we would see another approach where we would see the datatype mostly the object data type which is a stream data type also called as categorical data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e2c1d3",
   "metadata": {},
   "source": [
    "we have two approach backward filling and forward filled.\n",
    "\n",
    "backward filling : in this we would be filling the data from down where the below data is filled in the next upper na field\n",
    "\n",
    "forward filling: in this we would be filling the data from the up where the upper data is filled in the below row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6277851",
   "metadata": {},
   "source": [
    ".info() tells me which data is categorical and which is numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a7708",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e13a257",
   "metadata": {},
   "source": [
    "basically in the same method fillna we would add a parameter method=\"ffill\" for forward filling and method=\"bfill\" for backward filling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7df16c",
   "metadata": {},
   "source": [
    "if axis = 1 then its column wise data filling and if axis=0 then row wise data filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f412275",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fillna(method=\"bfill\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4329d438",
   "metadata": {},
   "source": [
    "another appraoch is mode filling, wherein we find out the most repeated data and then in the missing place we add that particular data\n",
    "mode can be found out a particular column only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e720cce2",
   "metadata": {},
   "source": [
    "calculating the mode of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33718684",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"duration\"].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"duration\"].fillna(dataset[\"duration\"].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c0045",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2abaf5",
   "metadata": {},
   "source": [
    "if we want to add the data to all the NA object fields then we would use this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc40a46",
   "metadata": {},
   "source": [
    "first we will find out all object type data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e48eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.select_dtypes(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ffe8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.select_dtypes(include=\"object\").isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e276c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset.select_dtypes(include=\"object\").isnull().columns:\n",
    "    dataset[i].fillna(dataset[i].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0b052d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
